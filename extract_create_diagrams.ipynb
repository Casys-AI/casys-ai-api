{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-26T05:24:51.402089400Z",
     "start_time": "2024-07-26T05:20:55.940144100Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\erpes\\PycharmProjects\\SysML_PLM\\venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:139: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 0.3.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import ChatOpenAI`.\n",
      "  warn_deprecated(\n",
      "C:\\Users\\erpes\\PycharmProjects\\SysML_PLM\\venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:139: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 0.3.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAIEmbeddings`.\n",
      "  warn_deprecated(\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 4066, which is longer than the specified 4000\n",
      "C:\\Users\\erpes\\PycharmProjects\\SysML_PLM\\venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:139: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n",
      "C:\\Users\\erpes\\PycharmProjects\\SysML_PLM\\venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:139: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "WARNING:__main__:Impossible de créer l'index vectoriel : Couldn't connect to localhost:7687 (resolved to ()):\n",
      "Failed to establish connection to ResolvedIPv6Address(('::1', 7687, 0, 0)) (reason [WinError 10061] Aucune connexion n’a pu être établie car l’ordinateur cible l’a expressément refusée)\n",
      "Failed to establish connection to ResolvedIPv4Address(('127.0.0.1', 7687)) (reason [WinError 10061] Aucune connexion n’a pu être établie car l’ordinateur cible l’a expressément refusée)\n",
      "WARNING:__main__:Erreur lors de la recherche vectorielle : Could not import tiktoken python package. This is needed in order to for OpenAIEmbeddings. Please install it with `pip install tiktoken`.\n",
      "INFO:__main__:Utilisation de la recherche par mot-clé comme solution de repli.\n",
      "ERROR:__main__:Erreur lors de la génération avec RAG : Session.run() got multiple values for argument 'query'\n",
      "INFO:__main__:RAG a échoué. Utilisation de la génération sans RAG comme solution de repli.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:__main__:Diagramme sauvegardé : diagrams/cdcs/cdc_1/REQ_diagram.md\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:__main__:Entités et relations sauvegardées : diagrams/cdcs/cdc_1/REQ_entities.json\n",
      "WARNING:__main__:Impossible de créer l'index vectoriel : Couldn't connect to localhost:7687 (resolved to ()):\n",
      "Failed to establish connection to ResolvedIPv6Address(('::1', 7687, 0, 0)) (reason [WinError 10061] Aucune connexion n’a pu être établie car l’ordinateur cible l’a expressément refusée)\n",
      "Failed to establish connection to ResolvedIPv4Address(('127.0.0.1', 7687)) (reason [WinError 10061] Aucune connexion n’a pu être établie car l’ordinateur cible l’a expressément refusée)\n",
      "WARNING:__main__:Erreur lors de la recherche vectorielle : Could not import tiktoken python package. This is needed in order to for OpenAIEmbeddings. Please install it with `pip install tiktoken`.\n",
      "INFO:__main__:Utilisation de la recherche par mot-clé comme solution de repli.\n",
      "ERROR:__main__:Erreur lors de la génération avec RAG : Session.run() got multiple values for argument 'query'\n",
      "INFO:__main__:RAG a échoué. Utilisation de la génération sans RAG comme solution de repli.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:__main__:Diagramme sauvegardé : diagrams/cdcs/cdc_1/UC_diagram.md\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:__main__:Entités et relations sauvegardées : diagrams/cdcs/cdc_1/UC_entities.json\n",
      "WARNING:__main__:Impossible de créer l'index vectoriel : Couldn't connect to localhost:7687 (resolved to ()):\n",
      "Failed to establish connection to ResolvedIPv6Address(('::1', 7687, 0, 0)) (reason [WinError 10061] Aucune connexion n’a pu être établie car l’ordinateur cible l’a expressément refusée)\n",
      "Failed to establish connection to ResolvedIPv4Address(('127.0.0.1', 7687)) (reason [WinError 10061] Aucune connexion n’a pu être établie car l’ordinateur cible l’a expressément refusée)\n",
      "WARNING:__main__:Erreur lors de la recherche vectorielle : Could not import tiktoken python package. This is needed in order to for OpenAIEmbeddings. Please install it with `pip install tiktoken`.\n",
      "INFO:__main__:Utilisation de la recherche par mot-clé comme solution de repli.\n",
      "ERROR:__main__:Erreur lors de la génération avec RAG : Session.run() got multiple values for argument 'query'\n",
      "INFO:__main__:RAG a échoué. Utilisation de la génération sans RAG comme solution de repli.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:__main__:Diagramme sauvegardé : diagrams/cdcs/cdc_1/BDD_diagram.md\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:__main__:Entités et relations sauvegardées : diagrams/cdcs/cdc_1/BDD_entities.json\n",
      "INFO:__main__:Extraction des entités et relations terminée pour le projet CDC_1.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "WARNING:__main__:Impossible de créer l'index vectoriel : Couldn't connect to localhost:7687 (resolved to ()):\n",
      "Failed to establish connection to ResolvedIPv6Address(('::1', 7687, 0, 0)) (reason [WinError 10061] Aucune connexion n’a pu être établie car l’ordinateur cible l’a expressément refusée)\n",
      "Failed to establish connection to ResolvedIPv4Address(('127.0.0.1', 7687)) (reason [WinError 10061] Aucune connexion n’a pu être établie car l’ordinateur cible l’a expressément refusée)\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "WARNING:__main__:Erreur lors de la recherche vectorielle : Couldn't connect to localhost:7687 (resolved to ()):\n",
      "Failed to establish connection to ResolvedIPv6Address(('::1', 7687, 0, 0)) (reason [WinError 10061] Aucune connexion n’a pu être établie car l’ordinateur cible l’a expressément refusée)\n",
      "Failed to establish connection to ResolvedIPv4Address(('127.0.0.1', 7687)) (reason [WinError 10061] Aucune connexion n’a pu être établie car l’ordinateur cible l’a expressément refusée)\n",
      "INFO:__main__:Utilisation de la recherche par mot-clé comme solution de repli.\n",
      "ERROR:__main__:Erreur lors de la génération avec RAG : Session.run() got multiple values for argument 'query'\n",
      "INFO:__main__:RAG a échoué. Utilisation de la génération sans RAG comme solution de repli.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:__main__:Diagramme sauvegardé : diagrams/parts/crushing_mill/crushing_mill_REQ_diagram.md\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:__main__:Entités et relations sauvegardées : diagrams/parts/crushing_mill/crushing_mill_REQ_entities.json\n",
      "WARNING:__main__:Impossible de créer l'index vectoriel : Couldn't connect to localhost:7687 (resolved to ()):\n",
      "Failed to establish connection to ResolvedIPv6Address(('::1', 7687, 0, 0)) (reason [WinError 10061] Aucune connexion n’a pu être établie car l’ordinateur cible l’a expressément refusée)\n",
      "Failed to establish connection to ResolvedIPv4Address(('127.0.0.1', 7687)) (reason [WinError 10061] Aucune connexion n’a pu être établie car l’ordinateur cible l’a expressément refusée)\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "WARNING:__main__:Erreur lors de la recherche vectorielle : Couldn't connect to localhost:7687 (resolved to ()):\n",
      "Failed to establish connection to ResolvedIPv6Address(('::1', 7687, 0, 0)) (reason [WinError 10061] Aucune connexion n’a pu être établie car l’ordinateur cible l’a expressément refusée)\n",
      "Failed to establish connection to ResolvedIPv4Address(('127.0.0.1', 7687)) (reason [WinError 10061] Aucune connexion n’a pu être établie car l’ordinateur cible l’a expressément refusée)\n",
      "INFO:__main__:Utilisation de la recherche par mot-clé comme solution de repli.\n",
      "ERROR:__main__:Erreur lors de la génération avec RAG : Session.run() got multiple values for argument 'query'\n",
      "INFO:__main__:RAG a échoué. Utilisation de la génération sans RAG comme solution de repli.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:__main__:Diagramme sauvegardé : diagrams/parts/crushing_mill/crushing_mill_UC_diagram.md\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:__main__:Entités et relations sauvegardées : diagrams/parts/crushing_mill/crushing_mill_UC_entities.json\n",
      "WARNING:__main__:Impossible de créer l'index vectoriel : Couldn't connect to localhost:7687 (resolved to ()):\n",
      "Failed to establish connection to ResolvedIPv6Address(('::1', 7687, 0, 0)) (reason [WinError 10061] Aucune connexion n’a pu être établie car l’ordinateur cible l’a expressément refusée)\n",
      "Failed to establish connection to ResolvedIPv4Address(('127.0.0.1', 7687)) (reason [WinError 10061] Aucune connexion n’a pu être établie car l’ordinateur cible l’a expressément refusée)\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "WARNING:__main__:Erreur lors de la recherche vectorielle : Couldn't connect to localhost:7687 (resolved to ()):\n",
      "Failed to establish connection to ResolvedIPv6Address(('::1', 7687, 0, 0)) (reason [WinError 10061] Aucune connexion n’a pu être établie car l’ordinateur cible l’a expressément refusée)\n",
      "Failed to establish connection to ResolvedIPv4Address(('127.0.0.1', 7687)) (reason [WinError 10061] Aucune connexion n’a pu être établie car l’ordinateur cible l’a expressément refusée)\n",
      "INFO:__main__:Utilisation de la recherche par mot-clé comme solution de repli.\n",
      "ERROR:__main__:Erreur lors de la génération avec RAG : Session.run() got multiple values for argument 'query'\n",
      "INFO:__main__:RAG a échoué. Utilisation de la génération sans RAG comme solution de repli.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:__main__:Diagramme sauvegardé : diagrams/parts/crushing_mill/crushing_mill_BDD_diagram.md\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:__main__:Entités et relations sauvegardées : diagrams/parts/crushing_mill/crushing_mill_BDD_entities.json\n",
      "INFO:__main__:Extraction des entités et relations terminée pour le projet CRUSHING_MILL.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import logging\n",
    "import yaml\n",
    "import json\n",
    "import re\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate, ChatPromptTemplate\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from neo4j import GraphDatabase\n",
    "from PyPDF2 import PdfReader\n",
    "from docx import Document as DocxDocument\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from tenacity import retry, stop_after_attempt, wait_random_exponential\n",
    "\n",
    "# Configuration du logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Charger la configuration à partir d'un fichier YAML\n",
    "with open(\"config.yaml\", \"r\") as config_file:\n",
    "    config = yaml.safe_load(config_file)\n",
    "\n",
    "# Initialisation de l'API OpenAI avec la configuration\n",
    "openai_chat = ChatOpenAI(\n",
    "    model_name=config[\"openai\"][\"model\"],\n",
    "    temperature=config[\"openai\"][\"temperature\"],\n",
    "    openai_api_key=config[\"openai\"][\"api_key\"]\n",
    ")\n",
    "\n",
    "# Initialisation de la connexion Neo4j\n",
    "neo4j_driver = GraphDatabase.driver(\n",
    "    config[\"neo4j\"][\"uri\"],\n",
    "    auth=(config[\"neo4j\"][\"user\"], config[\"neo4j\"][\"password\"])\n",
    ")\n",
    "\n",
    "# Initialisation du modèle d'embeddings\n",
    "embeddings_model = OpenAIEmbeddings(openai_api_key=config[\"openai\"][\"api_key\"])\n",
    "\n",
    "def create_vector_index(session):\n",
    "    try:\n",
    "        session.run(\"\"\"\n",
    "        CALL db.index.vector.createNodeIndex(\n",
    "          'entity_embeddings',\n",
    "          'Entity',\n",
    "          'embedding',\n",
    "          1536,\n",
    "          'cosine'\n",
    "        )\n",
    "        \"\"\")\n",
    "        logger.info(\"Index vectoriel 'entity_embeddings' créé avec succès.\")\n",
    "    except Exception as e:\n",
    "        if \"An equivalent index already exists\" in str(e):\n",
    "            logger.info(\"L'index vectoriel existe déjà.\")\n",
    "        else:\n",
    "            logger.warning(f\"Impossible de créer l'index vectoriel : {str(e)}\")\n",
    "\n",
    "def hybrid_search_with_fallback(query, semantic_top_k=5, graph_depth=2):\n",
    "    with neo4j_driver.session() as session:\n",
    "        try:\n",
    "            create_vector_index(session)\n",
    "            query_embedding = embeddings_model.embed_query(query)\n",
    "            semantic_results = session.run(\"\"\"\n",
    "            CALL db.index.vector.queryNodes('entity_embeddings', $k, $embedding)\n",
    "            YIELD node, score\n",
    "            RETURN node.name AS name, node.description AS description, score\n",
    "            \"\"\", k=semantic_top_k, embedding=query_embedding).data()\n",
    "        except Exception as e:\n",
    "            logger.warning(f\"Erreur lors de la recherche vectorielle : {str(e)}\")\n",
    "            logger.info(\"Utilisation de la recherche par mot-clé comme solution de repli.\")\n",
    "            semantic_results = session.run(\"\"\"\n",
    "            MATCH (e:Entity)\n",
    "            WHERE e.name CONTAINS $query OR e.description CONTAINS $query\n",
    "            RETURN e.name AS name, e.description AS description, 1.0 AS score\n",
    "            LIMIT $k\n",
    "            \"\"\", query=query, k=semantic_top_k).data()\n",
    "        \n",
    "        semantic_entity_names = [result['name'] for result in semantic_results]\n",
    "        graph_results = session.run(\"\"\"\n",
    "        MATCH (e:Entity)\n",
    "        WHERE e.name IN $entity_names\n",
    "        CALL apoc.path.subgraphNodes(e, {\n",
    "            maxLevel: $max_depth,\n",
    "            relationshipFilter: '>',\n",
    "            labelFilter: '+Entity'\n",
    "        })\n",
    "        YIELD node\n",
    "        RETURN DISTINCT node.name AS name, node.description AS description\n",
    "        \"\"\", entity_names=semantic_entity_names, max_depth=graph_depth).data()\n",
    "        \n",
    "        all_results = set([(r['name'], r['description']) for r in semantic_results + graph_results])\n",
    "        return list(all_results)\n",
    "\n",
    "def rag_pipeline(content, prompt_template):\n",
    "    try:\n",
    "        relevant_entities = hybrid_search_with_fallback(content)\n",
    "        context = \"Entités pertinentes trouvées :\\n\" + \"\\n\".join([f\"- {name}: {description}\" for name, description in relevant_entities])\n",
    "        enriched_prompt = f\"{context}\\n\\n{prompt_template}\\n\\nContenu à analyser :\\n{content}\"\n",
    "        prompt = PromptTemplate.from_template(enriched_prompt)\n",
    "        chain = prompt | openai_chat\n",
    "        result = chain.invoke({\"content\": content})\n",
    "        return result.content, True\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Erreur lors de la génération avec RAG : {str(e)}\")\n",
    "        return None, False\n",
    "\n",
    "def generate_with_fallback(prompt_template, content):\n",
    "    rag_result, rag_success = rag_pipeline(content, prompt_template)\n",
    "    if rag_success:\n",
    "        return rag_result\n",
    "    logger.info(\"RAG a échoué. Utilisation de la génération sans RAG comme solution de repli.\")\n",
    "    prompt = PromptTemplate.from_template(prompt_template)\n",
    "    chain = prompt | openai_chat\n",
    "    result = chain.invoke({\"content\": content})\n",
    "    return result.content\n",
    "\n",
    "def load_document(file_path):\n",
    "    if file_path.endswith(\".pdf\"):\n",
    "        with open(file_path, \"rb\") as file:\n",
    "            pdf_reader = PdfReader(file)\n",
    "            return \" \".join(page.extract_text() for page in pdf_reader.pages)\n",
    "    elif file_path.endswith(\".docx\"):\n",
    "        docx_doc = DocxDocument(file_path)\n",
    "        return \" \".join(para.text for para in docx_doc.paragraphs)\n",
    "    else:\n",
    "        raise ValueError(f\"Format de fichier non supporté : {file_path}\")\n",
    "\n",
    "def split_text(text, chunk_size=4000, chunk_overlap=200):\n",
    "    text_splitter = CharacterTextSplitter(\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=chunk_overlap,\n",
    "        length_function=len,\n",
    "        is_separator_regex=False\n",
    "    )\n",
    "    texts = text_splitter.split_text(text)\n",
    "    return [Document(page_content=t) for t in texts]\n",
    "\n",
    "def process_document(doc):\n",
    "    chain = load_summarize_chain(openai_chat, chain_type=\"stuff\")\n",
    "    return chain.run([doc])\n",
    "\n",
    "def summarize_text_parallel(docs, max_workers=5):\n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        summaries = list(executor.map(process_document, docs))\n",
    "    return \" \".join(summaries)\n",
    "\n",
    "@retry(wait=wait_random_exponential(min=1, max=60), stop=stop_after_attempt(5))\n",
    "def generate_diagram_with_retry(prompt_template_path, content=\"\"):\n",
    "    try:\n",
    "        with open(prompt_template_path, \"r\", encoding='utf-8') as template_file:\n",
    "            prompt_template = template_file.read()\n",
    "        return generate_with_fallback(prompt_template, content)\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error generating diagram: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "def extract_entities_and_relationships(diagram_content):\n",
    "    prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "    Analysez le contenu suivant et extrayez les entités et leurs relations :\n",
    "    \n",
    "    {content}\n",
    "    \n",
    "    Fournissez la sortie au format JSON avec la structure suivante :\n",
    "    {{\n",
    "        \"entities\": [\n",
    "            {{\n",
    "                \"name\": \"<nom_entité>\",\n",
    "                \"type\": \"<type_entité>\",\n",
    "                \"description\": \"<description_entité>\",\n",
    "                \"keywords\": [\"<mot_clé1>\", \"<mot_clé2>\", ...]\n",
    "            }},\n",
    "            ...\n",
    "        ],\n",
    "        \"relationships\": [\n",
    "            {{\n",
    "                \"source\": \"<entité_source>\",\n",
    "                \"target\": \"<entité_cible>\",\n",
    "                \"type\": \"<type_relation>\"\n",
    "            }},\n",
    "            ...\n",
    "        ]\n",
    "    }}\n",
    "    \n",
    "    Assurez-vous que la sortie est un JSON valide sans aucun texte supplémentaire.\n",
    "    \"\"\")\n",
    "    \n",
    "    chain = prompt | openai_chat\n",
    "    result = chain.invoke({\"content\": diagram_content})\n",
    "    \n",
    "    try:\n",
    "        json_content = re.search(r'\\{.*\\}', result.content, re.DOTALL)\n",
    "        if json_content:\n",
    "            return json.loads(json_content.group())\n",
    "        raise ValueError(\"Aucun contenu JSON trouvé dans la réponse\")\n",
    "    except json.JSONDecodeError as e:\n",
    "        logger.error(f\"Erreur lors du décodage JSON : {e}\")\n",
    "        logger.error(f\"Contenu reçu : {result.content}\")\n",
    "        return {\"entities\": [], \"relationships\": []}\n",
    "\n",
    "def save_entities_and_relationships(data, file_path):\n",
    "    os.makedirs(os.path.dirname(file_path), exist_ok=True)\n",
    "    with open(file_path, 'w', encoding='utf-8') as file:\n",
    "        json.dump(data, file, ensure_ascii=False, indent=2)\n",
    "    logger.info(f\"Entités et relations sauvegardées : {file_path}\")\n",
    "\n",
    "def save_diagram(diagram, file_path):\n",
    "    os.makedirs(os.path.dirname(file_path), exist_ok=True)\n",
    "    with open(file_path, 'w', encoding='utf-8') as file:\n",
    "        file.write(diagram)\n",
    "    logger.info(f\"Diagramme sauvegardé : {file_path}\")\n",
    "\n",
    "def get_file_paths(config, project_type, project_name):\n",
    "    template = config['file_templates'][project_type]\n",
    "    return {\n",
    "        diagram_type: {\n",
    "            'prompt': template['prompt'].format(cdc_name=project_name, part_name=project_name, diagram_type=diagram_type),\n",
    "            'output': template['output'].format(cdc_name=project_name, part_name=project_name, diagram_type=diagram_type),\n",
    "            'entities': template['entities'].format(cdc_name=project_name, part_name=project_name, diagram_type=diagram_type)\n",
    "        } for diagram_type in config['diagram_types']\n",
    "    }\n",
    "\n",
    "def process_project(config, project_type, project):\n",
    "    file_paths = get_file_paths(config, project_type, project['name'])\n",
    "    content = load_document(project['path'])\n",
    "    docs = split_text(content, \n",
    "                      chunk_size=config[\"text_splitter\"][\"chunk_size\"],\n",
    "                      chunk_overlap=config[\"text_splitter\"][\"chunk_overlap\"])\n",
    "    summary = summarize_text_parallel(docs)\n",
    "    \n",
    "    for diagram_type in config['diagram_types']:\n",
    "        diagram_content = generate_diagram_with_retry(file_paths[diagram_type]['prompt'], content=summary)\n",
    "        save_diagram(diagram_content, file_paths[diagram_type]['output'])\n",
    "        \n",
    "        entities = extract_entities_and_relationships(diagram_content)\n",
    "        save_entities_and_relationships(entities, file_paths[diagram_type]['entities'])\n",
    "    \n",
    "    logger.info(f\"Extraction des entités et relations terminée pour le projet {project['label']}.\")\n",
    "\n",
    "def main(config):\n",
    "    for project_type in ['cdcs', 'parts']:\n",
    "        for project in config['projects'][project_type]:\n",
    "            try:\n",
    "                process_project(config, project_type[:-1], project)  # Remove 's' from project_type\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Une erreur est survenue lors du traitement de {project['name']} : {str(e)}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# with gds for larger datasets \n",
    "(ne fonctionne pas pour le moment, pas de similarité trouvée entre les graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:__main__:L'index vectoriel existe probablement déjà : {code: Neo.ClientError.Procedure.ProcedureCallFailed} {message: Failed to invoke procedure `db.index.vector.createNodeIndex`: Caused by: org.neo4j.kernel.api.exceptions.schema.EquivalentSchemaRuleAlreadyExistsException: An equivalent index already exists, 'Index( id=3, name='entity_embeddings', type='VECTOR', schema=(:Entity {embedding}), indexProvider='vector-1.0' )'.}\n",
      "INFO:__main__:Creating or updating entities and relationships in Neo4j...\n",
      "INFO:__main__:Updating embeddings...\n",
      "INFO:__main__:Entities to update embeddings: 23\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:__main__:Updated embeddings for batch: ['BDD_B-005: Coffee Quality System', 'BDD_B-006: Control Algorithm System', 'REQ_mainReq', 'REQ_waterHeating', 'REQ_heatingPerformance', 'REQ_pressureControl', 'REQ_pressurePerformance', 'REQ_userInterface', 'REQ_coffeeQuality', 'REQ_controlAlgorithm', 'UC_User', 'UC_Maintenance Personnel', 'UC_CoffeeMachineSystem', 'UC_UC-001: Brew Coffee', 'UC_UC-002: Heat Water', 'UC_UC-003: Control Pressure', 'UC_UC-004: User Interface', 'UC_UC-005: Maintain Coffee Quality', 'UC_UC-006: Implement Control Algorithm', 'BDD_B-001: Coffee Machine System', 'BDD_B-002: Water Heating System', 'BDD_B-003: Pressure Control System', 'BDD_B-004: User Interface System']\n",
      "INFO:__main__:Embeddings updated successfully.\n",
      "INFO:__main__:Finding and linking similar entities across diagrams...\n",
      "INFO:__main__:Pas de projection de graphe existante à supprimer : {code: Neo.ClientError.Procedure.ProcedureCallFailed} {message: Failed to invoke procedure `gds.graph.drop`: Caused by: java.util.NoSuchElementException: Graph with name `entityGraph` does not exist on database `neo4j`. It might exist on another database.}\n",
      "INFO:__main__:Création d'une nouvelle projection de graphe en mémoire.\n",
      "INFO:__main__:Calcul des similarités cosinus.\n",
      "INFO:__main__:Similarities found: []\n",
      "WARNING:__main__:No similarities found to create relationships.\n",
      "INFO:__main__:SysML entities and relationships stored in Neo4j with intra-diagram links and inter-diagram similarity links.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import logging\n",
    "import yaml\n",
    "from typing import List, Dict, Any\n",
    "import numpy as np\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from neo4j import GraphDatabase\n",
    "from openai import OpenAI\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from dotenv import load_dotenv\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Configuration du logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Charger les variables d'environnement\n",
    "load_dotenv()\n",
    "\n",
    "# Charger la configuration à partir d'un fichier YAML\n",
    "with open(\"config.yaml\", \"r\") as config_file:\n",
    "    config = yaml.safe_load(config_file)\n",
    "\n",
    "# Configuration\n",
    "NEO4J_URI = config[\"neo4j\"][\"uri\"]\n",
    "NEO4J_USER = config[\"neo4j\"][\"user\"]\n",
    "NEO4J_PASSWORD = config[\"neo4j\"][\"password\"]\n",
    "OPENAI_API_KEY = config[\"openai\"][\"api_key\"]\n",
    "PROJECT_LABEL = \"CDC_1\"  # Label pour le projet en cours\n",
    "\n",
    "# Initialisation des clients\n",
    "openai_client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "embeddings_model = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)\n",
    "\n",
    "class Neo4jConnection:\n",
    "    def __init__(self, uri: str, user: str, password: str):\n",
    "        self.driver = GraphDatabase.driver(uri, auth=(user, password))\n",
    "\n",
    "    def close(self):\n",
    "        self.driver.close()\n",
    "\n",
    "    def run_query(self, query: str, parameters: Dict = None) -> List[Dict]:\n",
    "        with self.driver.session() as session:\n",
    "            result = session.run(query, parameters or {})\n",
    "            return [record.data() for record in result]\n",
    "\n",
    "    def ensure_vector_index(self):\n",
    "        try:\n",
    "            self.run_query(\"\"\"\n",
    "            CALL db.index.vector.createNodeIndex(\n",
    "              'entity_embeddings',\n",
    "              'Entity',\n",
    "              'embedding',\n",
    "              1536,\n",
    "              'cosine'\n",
    "            )\n",
    "            \"\"\")\n",
    "            logger.info(\"Index vectoriel 'entity_embeddings' créé avec succès.\")\n",
    "        except Exception as e:\n",
    "            logger.warning(f\"L'index vectoriel existe probablement déjà : {e}\")\n",
    "\n",
    "def batch_create_or_update_entities(tx, entities: List[Dict[str, Any]], project_label: str):\n",
    "    query = \"\"\"\n",
    "    UNWIND $entities AS entity\n",
    "    MERGE (e:Entity {id: entity.id})\n",
    "    SET e += entity.properties\n",
    "    WITH e, entity\n",
    "    CALL apoc.create.addLabels(e, [entity.diagramType, $project_label]) YIELD node\n",
    "    WITH node, entity\n",
    "    UNWIND entity.keywords AS keyword\n",
    "    MERGE (k:Keyword {name: keyword})\n",
    "    MERGE (node)-[:HAS_KEYWORD]->(k)\n",
    "    \"\"\"\n",
    "    tx.run(query, entities=[{\n",
    "        'id': f\"{entity['diagramType']}_{entity['name']}\",\n",
    "        'properties': {\n",
    "            'name': entity['name'],\n",
    "            'type': entity['type'],\n",
    "            'description': entity['description'],\n",
    "            'keywords': entity['keywords']\n",
    "        },\n",
    "        'diagramType': entity['diagramType']\n",
    "    } for entity in entities], project_label=project_label)\n",
    "\n",
    "def batch_create_relationships(tx, relationships: List[Dict[str, Any]], project_label: str):\n",
    "    query = \"\"\"\n",
    "    UNWIND $relationships AS rel\n",
    "    MATCH (s:Entity {id: rel.source_id}), (t:Entity {id: rel.target_id})\n",
    "    WHERE $project_label IN labels(s) AND $project_label IN labels(t)\n",
    "    CALL apoc.merge.relationship(s, rel.type, {}, {}, t) YIELD rel AS created_rel\n",
    "    RETURN count(created_rel)\n",
    "    \"\"\"\n",
    "    tx.run(query, relationships=[{\n",
    "        'source_id': f\"{rel['sourceDiagram']}_{rel['source']}\",\n",
    "        'target_id': f\"{rel['targetDiagram']}_{rel['target']}\",\n",
    "        'type': rel['type'].replace(' ', '_').upper()\n",
    "    } for rel in relationships], project_label=project_label)\n",
    "\n",
    "def update_embeddings(neo4j_connection: Neo4jConnection, project_label: str):\n",
    "    query = f\"\"\"\n",
    "    MATCH (e:Entity:{project_label})\n",
    "    WHERE e.description IS NOT NULL AND e.embedding IS NULL\n",
    "    RETURN e.id AS id, e.description AS description\n",
    "    \"\"\"\n",
    "    results = neo4j_connection.run_query(query)\n",
    "    logger.info(f\"Entities to update embeddings: {len(results)}\")\n",
    "    \n",
    "    def process_embeddings(records):\n",
    "        descriptions = [record['description'] for record in records]\n",
    "        embeddings = embeddings_model.embed_documents(descriptions)\n",
    "        return list(zip(records, embeddings))\n",
    "\n",
    "    def update_batch(batch):\n",
    "        update_query = \"\"\"\n",
    "        UNWIND $batch AS item\n",
    "        MATCH (e:Entity {id: item.id})\n",
    "        SET e.embedding = item.embedding\n",
    "        \"\"\"\n",
    "        neo4j_connection.run_query(update_query, {'batch': [\n",
    "            {'id': item[0]['id'], 'embedding': item[1]} for item in batch\n",
    "        ]})\n",
    "        logger.info(f\"Updated embeddings for batch: {[item[0]['id'] for item in batch]}\")\n",
    "\n",
    "    batch_size = 50\n",
    "    with ThreadPoolExecutor(max_workers=5) as executor:\n",
    "        futures = []\n",
    "        for i in range(0, len(results), batch_size):\n",
    "            batch = results[i:i+batch_size]\n",
    "            future = executor.submit(process_embeddings, batch)\n",
    "            futures.append(future)\n",
    "        \n",
    "        for future in as_completed(futures):\n",
    "            processed_batch = future.result()\n",
    "            update_batch(processed_batch)\n",
    "\n",
    "    logger.info(\"Embeddings updated successfully.\")\n",
    "\n",
    "def calculate_similarities_with_gds(neo4j_connection: Neo4jConnection, project_label: str):\n",
    "    # Vérifier si la projection de graphe existe déjà et la supprimer si nécessaire\n",
    "    try:\n",
    "        neo4j_connection.run_query(\"CALL gds.graph.drop('entityGraph')\")\n",
    "        logger.info(\"Ancienne projection de graphe 'entityGraph' supprimée.\")\n",
    "    except Exception as e:\n",
    "        logger.info(f\"Pas de projection de graphe existante à supprimer : {e}\")\n",
    "    \n",
    "    # Création d'une nouvelle projection de graphe en mémoire\n",
    "    logger.info(\"Création d'une nouvelle projection de graphe en mémoire.\")\n",
    "    neo4j_connection.run_query(f\"\"\"\n",
    "    CALL gds.graph.project(\n",
    "      'entityGraph',\n",
    "      ['Entity'],\n",
    "      '*',\n",
    "      {{\n",
    "        nodeProperties: ['embedding']\n",
    "      }}\n",
    "    )\n",
    "    \"\"\")\n",
    "    \n",
    "    # Calcul des similarités cosinus\n",
    "    logger.info(\"Calcul des similarités cosinus.\")\n",
    "    similarities = neo4j_connection.run_query(f\"\"\"\n",
    "    CALL gds.nodeSimilarity.stream('entityGraph', {{\n",
    "      similarityCutoff: 0.5,\n",
    "      topK: 10\n",
    "    }})\n",
    "    YIELD node1, node2, similarity\n",
    "    WITH gds.util.asNode(node1) AS entity1, gds.util.asNode(node2) AS entity2, similarity\n",
    "    WHERE entity1.diagramType <> entity2.diagramType\n",
    "      AND entity1:{project_label} AND entity2:{project_label}\n",
    "    RETURN entity1.id AS id1, entity2.id AS id2, similarity\n",
    "    \"\"\")\n",
    "    \n",
    "    logger.info(f\"Similarities found: {similarities}\")\n",
    "    \n",
    "    # Suppression de la projection du graphe\n",
    "    neo4j_connection.run_query(\"CALL gds.graph.drop('entityGraph')\")\n",
    "    \n",
    "    return similarities\n",
    "\n",
    "def create_similarity_relations_with_gds(neo4j_connection: Neo4jConnection, similarities: List[Dict], project_label: str):\n",
    "    logger.info(f\"Creating similarity relationships for {len(similarities)} pairs.\")\n",
    "    query = f\"\"\"\n",
    "    UNWIND $similarities AS sim\n",
    "    MATCH (e1:Entity:{project_label} {{id: sim.id1}}), (e2:Entity:{project_label} {{id: sim.id2}})\n",
    "    MERGE (e1)-[r:SIMILAR_TO]->(e2)\n",
    "    SET r.score = sim.similarity\n",
    "    \"\"\"\n",
    "    neo4j_connection.run_query(query, {'similarities': similarities})\n",
    "    logger.info(\"Similarity relationships created successfully.\")\n",
    "\n",
    "def process_json_file(file_path: str) -> Dict[str, Any]:\n",
    "    try:\n",
    "        with open(file_path, \"r\", encoding='utf-8') as f:\n",
    "            data = json.load(f)\n",
    "        return data\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error processing {file_path}: {e}\")\n",
    "        return {\"entities\": [], \"relationships\": []}\n",
    "\n",
    "def main():\n",
    "    neo4j_connection = Neo4jConnection(NEO4J_URI, NEO4J_USER, NEO4J_PASSWORD)\n",
    "    neo4j_connection.ensure_vector_index()\n",
    "\n",
    "    json_files = {\n",
    "        \"REQ\": \"diagrams/requirements_entities.json\",\n",
    "        \"UC\": \"diagrams/use_case_entities.json\",\n",
    "        \"BDD\": \"diagrams/block_definition_entities.json\"\n",
    "    }\n",
    "\n",
    "    all_entities = []\n",
    "    all_relationships = []\n",
    "\n",
    "    try:\n",
    "        with ThreadPoolExecutor(max_workers=5) as executor:\n",
    "            future_to_file = {executor.submit(process_json_file, file_path): (diagram_type, file_path) for diagram_type, file_path in json_files.items()}\n",
    "            for future in as_completed(future_to_file):\n",
    "                diagram_type, file_path = future_to_file[future]\n",
    "                data = future.result()\n",
    "                for entity in data['entities']:\n",
    "                    entity['diagramType'] = diagram_type\n",
    "                    all_entities.append(entity)\n",
    "                for relationship in data['relationships']:\n",
    "                    relationship['sourceDiagram'] = diagram_type\n",
    "                    relationship['targetDiagram'] = diagram_type\n",
    "                all_relationships.extend(data['relationships'])\n",
    "\n",
    "        if not all_entities or not all_relationships:\n",
    "            raise ValueError(\"No valid entities or relationships found in any JSON file.\")\n",
    "\n",
    "        logger.info(\"Creating or updating entities and relationships in Neo4j...\")\n",
    "        with neo4j_connection.driver.session() as session:\n",
    "            session.execute_write(batch_create_or_update_entities, all_entities, PROJECT_LABEL)\n",
    "            session.execute_write(batch_create_relationships, all_relationships, PROJECT_LABEL)\n",
    "\n",
    "        logger.info(\"Updating embeddings...\")\n",
    "        update_embeddings(neo4j_connection, PROJECT_LABEL)\n",
    "\n",
    "        logger.info(\"Finding and linking similar entities across diagrams...\")\n",
    "        similarities = calculate_similarities_with_gds(neo4j_connection, PROJECT_LABEL)\n",
    "        if similarities:\n",
    "            create_similarity_relations_with_gds(neo4j_connection, similarities, PROJECT_LABEL)\n",
    "        else:\n",
    "            logger.warning(\"No similarities found to create relationships.\")\n",
    "\n",
    "        logger.info(\"SysML entities and relationships stored in Neo4j with intra-diagram links and inter-diagram similarity links.\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"An error occurred: {e}\")\n",
    "        logger.info(\"Performing rollback...\")\n",
    "        neo4j_connection.run_query(f\"MATCH (n:{PROJECT_LABEL}) DETACH DELETE n\")\n",
    "    finally:\n",
    "        neo4j_connection.close()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
